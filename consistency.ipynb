{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6,7\"\n",
    "\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig\n",
    "import joblib\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from argparse import ArgumentParser\n",
    "import src.utils as utils\n",
    "from src.utils import normalize_answer, find_subsequence, exact_match_score\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------Greedy------------------\n",
      "EM: 43.22\n",
      "F1: 53.61\n",
      "\n",
      "------------------Consistency------------------\n",
      "EM: 42.370000000000005\n",
      "F1: 53.59\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = utils.load_parquet_data('results/llama-2-7b-hf/HotpotQA-2000-2per-seed0-cons3.parquet')\n",
    "\n",
    "# evaluate Greedy\n",
    "print('------------------Greedy------------------')\n",
    "greedy_em, _, _ = utils.evaluate_em(data, 'gold_ans', 'greedy_ans')\n",
    "greedy_f1, _, _ = utils.evaluate_f1(data, 'gold_ans', 'greedy_ans')\n",
    "\n",
    "print(f\"EM: {greedy_em * 100}\")\n",
    "print(f\"F1: {greedy_f1 * 100}\\n\")\n",
    "\n",
    "# evaluate RAG Hallu\n",
    "print('------------------Consistency------------------')\n",
    "ours_em, _, _ = utils.evaluate_em(data, 'gold_ans', 'pred_ans')\n",
    "ours_f1, _, _ = utils.evaluate_f1(data, 'gold_ans', 'pred_ans')\n",
    "\n",
    "\n",
    "print(f\"EM: {ours_em * 100}\")\n",
    "print(f\"F1: {ours_f1 * 100}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Total: 118\n",
      "--------------------------------------------------\n",
      "(O, TN) Consistent when correct: 43\n",
      "(X, FP) Inconsistent when correct: 7\n",
      "(X, FN) Consistent when incorrect: 28\n",
      "(O, TP) Inconsistent when incorrect: 40\n",
      "--------------------------------------------------\n",
      "Detection Accuracy: 0.7034\n",
      "Detection F1-score: 0.6957\n"
     ]
    }
   ],
   "source": [
    "correct = []\n",
    "incorrect = []\n",
    "\n",
    "correct_consistency = []\n",
    "incorrect_consistency = []\n",
    "\n",
    "for i, item in enumerate(data):\n",
    "\n",
    "    if exact_match_score(item['gold_ans'][0], item['pred_ans']):\n",
    "        correct.append(item)\n",
    "        correct_consistency.append(item['greedy_ans'] == item['pred_ans'])\n",
    "    else:\n",
    "        incorrect.append(item)\n",
    "        incorrect_consistency.append(item['greedy_ans'] == item['pred_ans'])\n",
    "\n",
    "print('-'*50)        \n",
    "print(f\"Total: {len(data)}\")\n",
    "print('-'*50)\n",
    "print(f\"(O, TN) Consistent when correct: {sum(correct_consistency)}\")\n",
    "print(f\"(X, FP) Inconsistent when correct: {len(correct_consistency) - sum(correct_consistency)}\")\n",
    "print(f\"(X, FN) Consistent when incorrect: {sum(incorrect_consistency)}\")\n",
    "print(f\"(O, TP) Inconsistent when incorrect: {len(incorrect_consistency) - sum(incorrect_consistency)}\")\n",
    "\n",
    "TP = len(incorrect_consistency) - sum(incorrect_consistency)\n",
    "TN = sum(correct_consistency)\n",
    "FP = len(correct_consistency) - sum(correct_consistency)\n",
    "FN = sum(incorrect_consistency)\n",
    "\n",
    "detection_accuracy = (TP + TN) / len(data)\n",
    "print('-'*50)\n",
    "print(f\"Detection Accuracy: {detection_accuracy:.4f}\")\n",
    "\n",
    "precision = TP / (TP + FP) if (TP + FP) > 0 else 0.0\n",
    "recall = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n",
    "f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "\n",
    "#print(f\"Detection Precision: {precision:.4f}\")\n",
    "#print(f\"Detection Recall: {recall:.4f}\")\n",
    "print(f\"Detection F1-score: {f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dagcd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
